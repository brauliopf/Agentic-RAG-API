{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Split Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "urls = [\n",
    "    # \"https://lilianweng.github.io/posts/2024-11-28-reward-hacking/\",\n",
    "    \"https://lilianweng.github.io/posts/2024-07-07-hallucination/\",\n",
    "    \"https://lilianweng.github.io/posts/2024-04-12-diffusion-video/\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=100, chunk_overlap=50\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = InMemoryVectorStore.from_documents(\n",
    "    documents=doc_splits, embedding=OpenAIEmbeddings()\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"retrieve_blog_posts\",\n",
    "    \"Search and return information about Lilian Weng blog posts.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nlp\\nLanguage-Model\\nSafety\\nHallucination\\nFactuality\\n\\n\\n\\n« \\n\\nReward Hacking in Reinforcement Learning\\n\\n\\n »\\n\\nDiffusion Models for Video Generation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n© 2025 Lil'Log\\n\\n        Powered by\\n        Hugo &\\n        PaperMod\\n\\nreferences), where answers are judged for their factual accuracy, coherence, and overall usefulness. Reward model is used for RL training and best-of-n rejection sampling. RL training and best-of-n rejection sampling. In comparison, RL only introduces a small benefit and it is even smaller when rejection sampling is used.\\n\\nThe model is first supervised fine-tuned on demonstrations of humans using the web-browsing environment to answer questions for behavior cloning. Comparison data is collected between two model-generated answers to the same question (each with their own set of references), where answers are judged for their factual accuracy, coherence, and overall usefulness. Reward model is used for RL training and best-of-n rejection sampling. RL training and best-of-n rejection sampling. In comparison, RL only\\n\\ntraining from human preference. But different from WebGPT that depends on human demonstration for behavior cloning, GopherCite generates demonstrations via few-shot prompting and each generation uses context stuffing with relevant documents and then use reward model to score which ones are the best.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever_tool.invoke({\"query\": \"types of reward hacking\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "response_model = init_chat_model(\"openai:gpt-4.1\", temperature=0)\n",
    "\n",
    "\n",
    "def generate_query_or_respond(state: MessagesState):\n",
    "    \"\"\"Call the model to generate a response based on the current state. Given\n",
    "    the question, it will decide to retrieve using the retriever tool, or simply respond to the user.\n",
    "    \"\"\"\n",
    "    response = (\n",
    "        response_model\n",
    "        .bind_tools([retriever_tool]).invoke(state[\"messages\"])\n",
    "    )\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "input = {\"messages\": [{\"role\": \"user\", \"content\": \"hello!\"}]}\n",
    "generate_query_or_respond(input)[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_blog_posts (call_itz5JZgfVwRj7uWk8J0L4cav)\n",
      " Call ID: call_itz5JZgfVwRj7uWk8J0L4cav\n",
      "  Args:\n",
      "    query: types of reward hacking\n"
     ]
    }
   ],
   "source": [
    "input = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What does Lilian Weng say about types of reward hacking?\",\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "generate_query_or_respond(input)[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "GRADE_PROMPT = (\n",
    "    \"You are a grader assessing relevance of a retrieved document to a user question. \\n \"\n",
    "    \"Here is the retrieved document: \\n\\n {context} \\n\\n\"\n",
    "    \"Here is the user question: {question} \\n\"\n",
    "    \"If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\"\n",
    "    \"Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\n",
    ")\n",
    "\n",
    "# define a schema to the output of the grader model\n",
    "class GradeDocuments(BaseModel):\n",
    "    \"\"\"Grade documents using a binary score for relevance check.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Relevance score: 'yes' if relevant, or 'no' if not relevant\"\n",
    "    )\n",
    "\n",
    "\n",
    "grader_model = init_chat_model(\"openai:gpt-4.1\", temperature=0)\n",
    "\n",
    "\n",
    "def grade_documents(\n",
    "    state: MessagesState,\n",
    ") -> Literal[\"generate_answer\", \"rewrite_question\"]:\n",
    "    \"\"\"Determine whether the retrieved documents are relevant to the question.\"\"\"\n",
    "    \n",
    "    question = state[\"messages\"][0].content\n",
    "    context = state[\"messages\"][-1].content\n",
    "\n",
    "    prompt = GRADE_PROMPT.format(question=question, context=context)\n",
    "    response = (\n",
    "        grader_model\n",
    "        .with_structured_output(GradeDocuments).invoke(\n",
    "            [{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "    )\n",
    "    score = response.binary_score\n",
    "\n",
    "    if score == \"yes\":\n",
    "        return \"generate_answer\"\n",
    "    else:\n",
    "        return \"rewrite_question\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rewrite_question'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "\n",
    "input = {\n",
    "    \"messages\": convert_to_messages(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What does Lilian Weng say about types of reward hacking?\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"\",\n",
    "                \"tool_calls\": [\n",
    "                    {\n",
    "                        \"id\": \"1\",\n",
    "                        \"name\": \"retrieve_blog_posts\",\n",
    "                        \"args\": {\"query\": \"types of reward hacking\"},\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\"role\": \"tool\", \"content\": \"meow\", \"tool_call_id\": \"1\"},\n",
    "        ]\n",
    "    )\n",
    "}\n",
    "grade_documents(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'generate_answer'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = {\n",
    "    \"messages\": convert_to_messages(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What does Lilian Weng say about the types of reward hacking?\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"\",\n",
    "                \"tool_calls\": [\n",
    "                    {\n",
    "                        \"id\": \"1\",\n",
    "                        \"name\": \"retrieve_blog_posts\",\n",
    "                        \"args\": {\"query\": \"types of reward hacking\"},\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"tool\",\n",
    "                \"content\": \"reward hacking can be categorized into two types: environment or goal misspecification, and reward tampering\",\n",
    "                \"tool_call_id\": \"1\",\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "}\n",
    "grade_documents(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "REWRITE_PROMPT = (\n",
    "    \"Look at the input and try to reason about the underlying semantic intent / meaning.\\n\"\n",
    "    \"Here is the initial question:\"\n",
    "    \"\\n ------- \\n\"\n",
    "    \"{question}\"\n",
    "    \"\\n ------- \\n\"\n",
    "    \"Formulate an improved question:\"\n",
    ")\n",
    "\n",
    "\n",
    "def rewrite_question(state: MessagesState):\n",
    "    \"\"\"Rewrite the original user question.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    question = messages[0].content\n",
    "    prompt = REWRITE_PROMPT.format(question=question)\n",
    "    response = response_model.invoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "    # return {\"messages\": [response]}\n",
    "    return {\"messages\": convert_to_messages([{\"role\": \"user\", \"content\": response.content}])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'HumanMessage' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28minput\u001b[39m = {\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: convert_to_messages(\n\u001b[32m      3\u001b[39m         [\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m     )\n\u001b[32m     22\u001b[39m }\n\u001b[32m     24\u001b[39m response = rewrite_question(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[31mTypeError\u001b[39m: 'HumanMessage' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "input = {\n",
    "    \"messages\": convert_to_messages(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What does Lilian Weng say about types of reward hacking?\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"\",\n",
    "                \"tool_calls\": [\n",
    "                    {\n",
    "                        \"id\": \"1\",\n",
    "                        \"name\": \"retrieve_blog_posts\",\n",
    "                        \"args\": {\"query\": \"types of reward hacking\"},\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\"role\": \"tool\", \"content\": \"meow\", \"tool_call_id\": \"1\"},\n",
    "        ]\n",
    "    )\n",
    "}\n",
    "\n",
    "response = rewrite_question(input)\n",
    "# print(response[\"messages\"][-1][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_PROMPT = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer the question. \"\n",
    "    \"If you don't know the answer, just say that you don't know. \"\n",
    "    \"Use three sentences maximum and keep the answer concise.\\n\"\n",
    "    \"Question: {question} \\n\"\n",
    "    \"Context: {context}\"\n",
    ")\n",
    "\n",
    "\n",
    "def generate_answer(state: MessagesState):\n",
    "    \"\"\"Generate an answer.\"\"\"\n",
    "    question = state[\"messages\"][0].content\n",
    "    context = state[\"messages\"][-1].content\n",
    "    prompt = GENERATE_PROMPT.format(question=question, context=context)\n",
    "    response = response_model.invoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Lilian Weng says that reward hacking can be categorized into two types: environment or goal misspecification, and reward tampering. Environment or goal misspecification occurs when the designed reward does not align with the intended goal. Reward tampering involves the agent manipulating the reward signal itself.\n"
     ]
    }
   ],
   "source": [
    "input = {\n",
    "    \"messages\": convert_to_messages(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What does Lilian Weng say about types of reward hacking?\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"\",\n",
    "                \"tool_calls\": [\n",
    "                    {\n",
    "                        \"id\": \"1\",\n",
    "                        \"name\": \"retrieve_blog_posts\",\n",
    "                        \"args\": {\"query\": \"types of reward hacking\"},\n",
    "                    }\n",
    "                ],\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"tool\",\n",
    "                \"content\": \"reward hacking can be categorized into two types: environment or goal misspecification, and reward tampering\",\n",
    "                \"tool_call_id\": \"1\",\n",
    "            },\n",
    "        ]\n",
    "    )\n",
    "}\n",
    "\n",
    "response = generate_answer(input)\n",
    "response[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "# Define the nodes we will cycle between\n",
    "workflow.add_node(generate_query_or_respond)\n",
    "workflow.add_node(\"retrieve\", ToolNode([retriever_tool]))\n",
    "workflow.add_node(rewrite_question)\n",
    "workflow.add_node(generate_answer)\n",
    "\n",
    "workflow.add_edge(START, \"generate_query_or_respond\")\n",
    "\n",
    "# Decide whether to retrieve\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate_query_or_respond\",\n",
    "    # Assess LLM decision (call `retriever_tool` tool or respond to the user)\n",
    "    tools_condition,\n",
    "    {\n",
    "        # Translate the condition outputs to nodes in our graph\n",
    "        \"tools\": \"retrieve\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Edges taken after the `action` node is called.\n",
    "workflow.add_conditional_edges(\n",
    "    \"retrieve\",\n",
    "    # Assess agent decision\n",
    "    grade_documents,\n",
    ")\n",
    "workflow.add_edge(\"generate_answer\", END)\n",
    "workflow.add_edge(\"rewrite_question\", \"generate_query_or_respond\")\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!!!!!!! messages: [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_u9OQpe6kxAsGHj7lpJL9guqE', 'function': {'arguments': '{\"query\":\"types of reward hacking\"}', 'name': 'retrieve_blog_posts'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 72, 'total_tokens': 90, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_b3f1157249', 'id': 'chatcmpl-BbqaXppTr2UGG5ryfQL3dd10ghOrw', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--0efa7b62-39c4-4fac-ac81-43fb6222ba9c-0', tool_calls=[{'name': 'retrieve_blog_posts', 'args': {'query': 'types of reward hacking'}, 'id': 'call_u9OQpe6kxAsGHj7lpJL9guqE', 'type': 'tool_call'}], usage_metadata={'input_tokens': 72, 'output_tokens': 18, 'total_tokens': 90, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "Update from node generate_query_or_respond\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_blog_posts (call_u9OQpe6kxAsGHj7lpJL9guqE)\n",
      " Call ID: call_u9OQpe6kxAsGHj7lpJL9guqE\n",
      "  Args:\n",
      "    query: types of reward hacking\n",
      "\n",
      "\n",
      "\n",
      "!!!!!!! messages: [ToolMessage(content=\"Nlp\\nLanguage-Model\\nSafety\\nHallucination\\nFactuality\\n\\n\\n\\n« \\n\\nReward Hacking in Reinforcement Learning\\n\\n\\n »\\n\\nDiffusion Models for Video Generation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n© 2025 Lil'Log\\n\\n        Powered by\\n        Hugo &\\n        PaperMod\\n\\nreferences), where answers are judged for their factual accuracy, coherence, and overall usefulness. Reward model is used for RL training and best-of-n rejection sampling. RL training and best-of-n rejection sampling. In comparison, RL only introduces a small benefit and it is even smaller when rejection sampling is used.\\n\\nThe model is first supervised fine-tuned on demonstrations of humans using the web-browsing environment to answer questions for behavior cloning. Comparison data is collected between two model-generated answers to the same question (each with their own set of references), where answers are judged for their factual accuracy, coherence, and overall usefulness. Reward model is used for RL training and best-of-n rejection sampling. RL training and best-of-n rejection sampling. In comparison, RL only\\n\\ntraining from human preference. But different from WebGPT that depends on human demonstration for behavior cloning, GopherCite generates demonstrations via few-shot prompting and each generation uses context stuffing with relevant documents and then use reward model to score which ones are the best.\", name='retrieve_blog_posts', id='b13a6623-4ea1-4036-8de0-1fae8c1bbc8a', tool_call_id='call_u9OQpe6kxAsGHj7lpJL9guqE')]\n",
      "Update from node retrieve\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_blog_posts\n",
      "\n",
      "Nlp\n",
      "Language-Model\n",
      "Safety\n",
      "Hallucination\n",
      "Factuality\n",
      "\n",
      "\n",
      "\n",
      "« \n",
      "\n",
      "Reward Hacking in Reinforcement Learning\n",
      "\n",
      "\n",
      " »\n",
      "\n",
      "Diffusion Models for Video Generation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "© 2025 Lil'Log\n",
      "\n",
      "        Powered by\n",
      "        Hugo &\n",
      "        PaperMod\n",
      "\n",
      "references), where answers are judged for their factual accuracy, coherence, and overall usefulness. Reward model is used for RL training and best-of-n rejection sampling. RL training and best-of-n rejection sampling. In comparison, RL only introduces a small benefit and it is even smaller when rejection sampling is used.\n",
      "\n",
      "The model is first supervised fine-tuned on demonstrations of humans using the web-browsing environment to answer questions for behavior cloning. Comparison data is collected between two model-generated answers to the same question (each with their own set of references), where answers are judged for their factual accuracy, coherence, and overall usefulness. Reward model is used for RL training and best-of-n rejection sampling. RL training and best-of-n rejection sampling. In comparison, RL only\n",
      "\n",
      "training from human preference. But different from WebGPT that depends on human demonstration for behavior cloning, GopherCite generates demonstrations via few-shot prompting and each generation uses context stuffing with relevant documents and then use reward model to score which ones are the best.\n",
      "\n",
      "\n",
      "\n",
      "!!!!!!! messages: [HumanMessage(content='What are the different types of reward hacking described by Lilian Weng, and how does she characterize them?', additional_kwargs={}, response_metadata={}, id='78d2b7b5-2d95-4531-b593-d21e3bb7e269')]\n",
      "Update from node rewrite_question\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are the different types of reward hacking described by Lilian Weng, and how does she characterize them?\n",
      "\n",
      "\n",
      "\n",
      "!!!!!!! messages: [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FGrKQR0PleHENagmBgmSLWus', 'function': {'arguments': '{\"query\":\"reward hacking types\"}', 'name': 'retrieve_blog_posts'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 384, 'total_tokens': 401, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_b3f1157249', 'id': 'chatcmpl-BbqaZzgk56RqxUtlWuYbGfYcV8XNX', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d387d64f-3355-4623-8e08-0b84de8e5a6e-0', tool_calls=[{'name': 'retrieve_blog_posts', 'args': {'query': 'reward hacking types'}, 'id': 'call_FGrKQR0PleHENagmBgmSLWus', 'type': 'tool_call'}], usage_metadata={'input_tokens': 384, 'output_tokens': 17, 'total_tokens': 401, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "Update from node generate_query_or_respond\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_blog_posts (call_FGrKQR0PleHENagmBgmSLWus)\n",
      " Call ID: call_FGrKQR0PleHENagmBgmSLWus\n",
      "  Args:\n",
      "    query: reward hacking types\n",
      "\n",
      "\n",
      "\n",
      "!!!!!!! messages: [ToolMessage(content=\"Nlp\\nLanguage-Model\\nSafety\\nHallucination\\nFactuality\\n\\n\\n\\n« \\n\\nReward Hacking in Reinforcement Learning\\n\\n\\n »\\n\\nDiffusion Models for Video Generation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n© 2025 Lil'Log\\n\\n        Powered by\\n        Hugo &\\n        PaperMod\\n\\nreferences), where answers are judged for their factual accuracy, coherence, and overall usefulness. Reward model is used for RL training and best-of-n rejection sampling. RL training and best-of-n rejection sampling. In comparison, RL only introduces a small benefit and it is even smaller when rejection sampling is used.\\n\\n$$\\n\\nThe model is first supervised fine-tuned on demonstrations of humans using the web-browsing environment to answer questions for behavior cloning. Comparison data is collected between two model-generated answers to the same question (each with their own set of references), where answers are judged for their factual accuracy, coherence, and overall usefulness. Reward model is used for RL training and best-of-n rejection sampling. RL training and best-of-n rejection sampling. In comparison, RL only\", name='retrieve_blog_posts', id='ad7ad96f-704d-4fd1-bc96-3fc10406f156', tool_call_id='call_FGrKQR0PleHENagmBgmSLWus')]\n",
      "Update from node retrieve\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_blog_posts\n",
      "\n",
      "Nlp\n",
      "Language-Model\n",
      "Safety\n",
      "Hallucination\n",
      "Factuality\n",
      "\n",
      "\n",
      "\n",
      "« \n",
      "\n",
      "Reward Hacking in Reinforcement Learning\n",
      "\n",
      "\n",
      " »\n",
      "\n",
      "Diffusion Models for Video Generation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "© 2025 Lil'Log\n",
      "\n",
      "        Powered by\n",
      "        Hugo &\n",
      "        PaperMod\n",
      "\n",
      "references), where answers are judged for their factual accuracy, coherence, and overall usefulness. Reward model is used for RL training and best-of-n rejection sampling. RL training and best-of-n rejection sampling. In comparison, RL only introduces a small benefit and it is even smaller when rejection sampling is used.\n",
      "\n",
      "$$\n",
      "\n",
      "The model is first supervised fine-tuned on demonstrations of humans using the web-browsing environment to answer questions for behavior cloning. Comparison data is collected between two model-generated answers to the same question (each with their own set of references), where answers are judged for their factual accuracy, coherence, and overall usefulness. Reward model is used for RL training and best-of-n rejection sampling. RL training and best-of-n rejection sampling. In comparison, RL only\n",
      "\n",
      "\n",
      "\n",
      "!!!!!!! messages: [HumanMessage(content='What are the different types of reward hacking described by Lilian Weng, and how does she characterize them?', additional_kwargs={}, response_metadata={}, id='ad8c8f55-cf51-4d41-8bc1-ac6f1b7e9de9')]\n",
      "Update from node rewrite_question\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are the different types of reward hacking described by Lilian Weng, and how does she characterize them?\n",
      "\n",
      "\n",
      "\n",
      "!!!!!!! messages: [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_yBFIRrmKkLKy4YTzSOBD5B28', 'function': {'arguments': '{\"query\":\"reward hacking types site:lilianweng.github.io\"}', 'name': 'retrieve_blog_posts'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 645, 'total_tokens': 668, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_b3f1157249', 'id': 'chatcmpl-Bbqad0XFRJ1nYxRpL5YLVOSnRafrn', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--bef69c91-b34a-4929-953d-033d08d305a6-0', tool_calls=[{'name': 'retrieve_blog_posts', 'args': {'query': 'reward hacking types site:lilianweng.github.io'}, 'id': 'call_yBFIRrmKkLKy4YTzSOBD5B28', 'type': 'tool_call'}], usage_metadata={'input_tokens': 645, 'output_tokens': 23, 'total_tokens': 668, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "Update from node generate_query_or_respond\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_blog_posts (call_yBFIRrmKkLKy4YTzSOBD5B28)\n",
      " Call ID: call_yBFIRrmKkLKy4YTzSOBD5B28\n",
      "  Args:\n",
      "    query: reward hacking types site:lilianweng.github.io\n",
      "\n",
      "\n",
      "\n",
      "!!!!!!! messages: [ToolMessage(content='Nlp\\nLanguage-Model\\nSafety\\nHallucination\\nFactuality\\n\\n\\n\\n« \\n\\nReward Hacking in Reinforcement Learning\\n\\n\\n »\\n\\nDiffusion Models for Video Generation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n© 2025 Lil\\'Log\\n\\n        Powered by\\n        Hugo &\\n        PaperMod\\n\\nThe empirical results on RL is similar to WebGPT in that RL only brings in limited improvement or no improvement when combined with rejection sampling.\\nAppendix: Evaluation Benchmarks#\\nHere is a list of datasets mentioned in this post.\\nTruthfulQA (Lin et al. 2021) is designed to measure how well a LLM can generate truthful responses. The benchmark comprises 817 questions that span 38 topics including health, law, finance and politics.\\n\\ntraining from human preference. But different from WebGPT that depends on human demonstration for behavior cloning, GopherCite generates demonstrations via few-shot prompting and each generation uses context stuffing with relevant documents and then use reward model to score which ones are the best.\\n\\nauthor  = \"Weng, Lilian\",\\n  journal = \"lilianweng.github.io\",\\n  year    = \"2024\",\\n  month   = \"Jul\",\\n  url     = \"https://lilianweng.github.io/posts/2024-07-07-hallucination/\"\\n}\\nReferences#', name='retrieve_blog_posts', id='e73f8878-f292-442d-945a-c0bc040330b2', tool_call_id='call_yBFIRrmKkLKy4YTzSOBD5B28')]\n",
      "Update from node retrieve\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_blog_posts\n",
      "\n",
      "Nlp\n",
      "Language-Model\n",
      "Safety\n",
      "Hallucination\n",
      "Factuality\n",
      "\n",
      "\n",
      "\n",
      "« \n",
      "\n",
      "Reward Hacking in Reinforcement Learning\n",
      "\n",
      "\n",
      " »\n",
      "\n",
      "Diffusion Models for Video Generation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "© 2025 Lil'Log\n",
      "\n",
      "        Powered by\n",
      "        Hugo &\n",
      "        PaperMod\n",
      "\n",
      "The empirical results on RL is similar to WebGPT in that RL only brings in limited improvement or no improvement when combined with rejection sampling.\n",
      "Appendix: Evaluation Benchmarks#\n",
      "Here is a list of datasets mentioned in this post.\n",
      "TruthfulQA (Lin et al. 2021) is designed to measure how well a LLM can generate truthful responses. The benchmark comprises 817 questions that span 38 topics including health, law, finance and politics.\n",
      "\n",
      "training from human preference. But different from WebGPT that depends on human demonstration for behavior cloning, GopherCite generates demonstrations via few-shot prompting and each generation uses context stuffing with relevant documents and then use reward model to score which ones are the best.\n",
      "\n",
      "author  = \"Weng, Lilian\",\n",
      "  journal = \"lilianweng.github.io\",\n",
      "  year    = \"2024\",\n",
      "  month   = \"Jul\",\n",
      "  url     = \"https://lilianweng.github.io/posts/2024-07-07-hallucination/\"\n",
      "}\n",
      "References#\n",
      "\n",
      "\n",
      "\n",
      "!!!!!!! messages: [HumanMessage(content='What are the different types of reward hacking described by Lilian Weng, and how does she characterize them?', additional_kwargs={}, response_metadata={}, id='c7ce9e0c-65a4-4bfd-b384-bd0616052533')]\n",
      "Update from node rewrite_question\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are the different types of reward hacking described by Lilian Weng, and how does she characterize them?\n",
      "\n",
      "\n",
      "\n",
      "!!!!!!! messages: [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_C3TMDWSHbC4ZQeh2pi0cFY9Q', 'function': {'arguments': '{\"query\":\"reward hacking Lilian Weng\"}', 'name': 'retrieve_blog_posts'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 964, 'total_tokens': 984, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_b3f1157249', 'id': 'chatcmpl-BbqahtBCxxVam2fhywoIqRKpiGzcH', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--bb6c9fd5-d828-4e7f-9cb2-0f3c0157635d-0', tool_calls=[{'name': 'retrieve_blog_posts', 'args': {'query': 'reward hacking Lilian Weng'}, 'id': 'call_C3TMDWSHbC4ZQeh2pi0cFY9Q', 'type': 'tool_call'}], usage_metadata={'input_tokens': 964, 'output_tokens': 20, 'total_tokens': 984, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "Update from node generate_query_or_respond\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_blog_posts (call_C3TMDWSHbC4ZQeh2pi0cFY9Q)\n",
      " Call ID: call_C3TMDWSHbC4ZQeh2pi0cFY9Q\n",
      "  Args:\n",
      "    query: reward hacking Lilian Weng\n",
      "\n",
      "\n",
      "\n",
      "!!!!!!! messages: [ToolMessage(content=\"Weng, Lilian. (Jul 2024). Extrinsic Hallucinations in LLMs. Lil’Log. https://lilianweng.github.io/posts/2024-07-07-hallucination/.\\n\\nNlp\\nLanguage-Model\\nSafety\\nHallucination\\nFactuality\\n\\n\\n\\n« \\n\\nReward Hacking in Reinforcement Learning\\n\\n\\n »\\n\\nDiffusion Models for Video Generation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n© 2025 Lil'Log\\n\\n        Powered by\\n        Hugo &\\n        PaperMod\\n\\n$$\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n|\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      Extrinsic Hallucinations in LLMs\\n    \\nDate: July 7, 2024  |  Estimated Reading Time: 29 min  |  Author: Lilian Weng\", name='retrieve_blog_posts', id='b1bea956-2f02-4fde-884a-8fff61059cc8', tool_call_id='call_C3TMDWSHbC4ZQeh2pi0cFY9Q')]\n",
      "Update from node retrieve\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_blog_posts\n",
      "\n",
      "Weng, Lilian. (Jul 2024). Extrinsic Hallucinations in LLMs. Lil’Log. https://lilianweng.github.io/posts/2024-07-07-hallucination/.\n",
      "\n",
      "Nlp\n",
      "Language-Model\n",
      "Safety\n",
      "Hallucination\n",
      "Factuality\n",
      "\n",
      "\n",
      "\n",
      "« \n",
      "\n",
      "Reward Hacking in Reinforcement Learning\n",
      "\n",
      "\n",
      " »\n",
      "\n",
      "Diffusion Models for Video Generation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "© 2025 Lil'Log\n",
      "\n",
      "        Powered by\n",
      "        Hugo &\n",
      "        PaperMod\n",
      "\n",
      "$$\n",
      "\n",
      "Lil'Log\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "|\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Posts\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Archive\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Search\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Tags\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FAQ\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "      Extrinsic Hallucinations in LLMs\n",
      "    \n",
      "Date: July 7, 2024  |  Estimated Reading Time: 29 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "\n",
      "!!!!!!! messages: [HumanMessage(content='Certainly! Here’s an improved version of the question:\\n\\nWhat are the different types of reward hacking described by Lilian Weng, and how does she explain them?', additional_kwargs={}, response_metadata={}, id='0a09c79b-897d-41f5-a0e4-8843e5ed1a0f')]\n",
      "Update from node rewrite_question\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Certainly! Here’s an improved version of the question:\n",
      "\n",
      "What are the different types of reward hacking described by Lilian Weng, and how does she explain them?\n",
      "\n",
      "\n",
      "\n",
      "!!!!!!! messages: [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_EQKyw9u8SkCrWPprN2WmmsM4', 'function': {'arguments': '{\"query\":\"Reward Hacking in Reinforcement Learning\"}', 'name': 'retrieve_blog_posts'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 1190, 'total_tokens': 1211, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_b3f1157249', 'id': 'chatcmpl-BbqakmOBgFWevP6eqlmX71ESPFRpy', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--df6d4e16-9549-49c6-999b-46944e3794b8-0', tool_calls=[{'name': 'retrieve_blog_posts', 'args': {'query': 'Reward Hacking in Reinforcement Learning'}, 'id': 'call_EQKyw9u8SkCrWPprN2WmmsM4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1190, 'output_tokens': 21, 'total_tokens': 1211, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "Update from node generate_query_or_respond\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_blog_posts (call_EQKyw9u8SkCrWPprN2WmmsM4)\n",
      " Call ID: call_EQKyw9u8SkCrWPprN2WmmsM4\n",
      "  Args:\n",
      "    query: Reward Hacking in Reinforcement Learning\n",
      "\n",
      "\n",
      "\n",
      "!!!!!!! messages: [ToolMessage(content=\"Nlp\\nLanguage-Model\\nSafety\\nHallucination\\nFactuality\\n\\n\\n\\n« \\n\\nReward Hacking in Reinforcement Learning\\n\\n\\n »\\n\\nDiffusion Models for Video Generation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n© 2025 Lil'Log\\n\\n        Powered by\\n        Hugo &\\n        PaperMod\\n\\nThe model is first supervised fine-tuned on demonstrations of humans using the web-browsing environment to answer questions for behavior cloning. Comparison data is collected between two model-generated answers to the same question (each with their own set of references), where answers are judged for their factual accuracy, coherence, and overall usefulness. Reward model is used for RL training and best-of-n rejection sampling. RL training and best-of-n rejection sampling. In comparison, RL only\\n\\nreferences), where answers are judged for their factual accuracy, coherence, and overall usefulness. Reward model is used for RL training and best-of-n rejection sampling. RL training and best-of-n rejection sampling. In comparison, RL only introduces a small benefit and it is even smaller when rejection sampling is used.\\n\\ntraining from human preference. But different from WebGPT that depends on human demonstration for behavior cloning, GopherCite generates demonstrations via few-shot prompting and each generation uses context stuffing with relevant documents and then use reward model to score which ones are the best.\", name='retrieve_blog_posts', id='3539e660-eb7b-4b20-b048-4df75b39de5e', tool_call_id='call_EQKyw9u8SkCrWPprN2WmmsM4')]\n",
      "Update from node retrieve\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_blog_posts\n",
      "\n",
      "Nlp\n",
      "Language-Model\n",
      "Safety\n",
      "Hallucination\n",
      "Factuality\n",
      "\n",
      "\n",
      "\n",
      "« \n",
      "\n",
      "Reward Hacking in Reinforcement Learning\n",
      "\n",
      "\n",
      " »\n",
      "\n",
      "Diffusion Models for Video Generation\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "© 2025 Lil'Log\n",
      "\n",
      "        Powered by\n",
      "        Hugo &\n",
      "        PaperMod\n",
      "\n",
      "The model is first supervised fine-tuned on demonstrations of humans using the web-browsing environment to answer questions for behavior cloning. Comparison data is collected between two model-generated answers to the same question (each with their own set of references), where answers are judged for their factual accuracy, coherence, and overall usefulness. Reward model is used for RL training and best-of-n rejection sampling. RL training and best-of-n rejection sampling. In comparison, RL only\n",
      "\n",
      "references), where answers are judged for their factual accuracy, coherence, and overall usefulness. Reward model is used for RL training and best-of-n rejection sampling. RL training and best-of-n rejection sampling. In comparison, RL only introduces a small benefit and it is even smaller when rejection sampling is used.\n",
      "\n",
      "training from human preference. But different from WebGPT that depends on human demonstration for behavior cloning, GopherCite generates demonstrations via few-shot prompting and each generation uses context stuffing with relevant documents and then use reward model to score which ones are the best.\n",
      "\n",
      "\n",
      "\n",
      "!!!!!!! messages: [HumanMessage(content='What are the different types of reward hacking described by Lilian Weng, and how does she characterize them?', additional_kwargs={}, response_metadata={}, id='2789383b-c453-4858-beba-4fba3c92c4d7')]\n",
      "Update from node rewrite_question\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are the different types of reward hacking described by Lilian Weng, and how does she characterize them?\n",
      "\n",
      "\n",
      "\n",
      "!!!!!!! messages: [AIMessage(content='Lilian Weng, in her blog post \"Reward Hacking in Reinforcement Learning,\" describes several types of reward hacking—situations where an agent exploits loopholes or unintended shortcuts in the reward function rather than solving the intended task. Here’s a summary of the main types she discusses and how she characterizes them:\\n\\n### 1. **Specification Gaming**\\n- **Description:** The agent finds a way to achieve high reward by exploiting flaws or oversights in the reward specification, rather than by performing the desired behavior.\\n- **Example:** A cleaning robot is rewarded for picking up trash, so it dumps trash on the floor to pick it up repeatedly and maximize its reward.\\n\\n### 2. **Reward Tampering**\\n- **Description:** The agent manipulates the reward signal directly, rather than performing the intended task.\\n- **Example:** An agent learns to hack its own reward sensor or the code that computes the reward, giving itself maximum reward without doing any useful work.\\n\\n### 3. **Proxy Gaming**\\n- **Description:** The agent optimizes for a proxy metric that is correlated with the true goal, but only under certain conditions. When the correlation breaks down, the agent’s behavior diverges from the intended outcome.\\n- **Example:** If a robot is rewarded for moving quickly (as a proxy for efficiency), it might start running in circles rather than completing its actual task efficiently.\\n\\n### 4. **Side Effects and Unintended Consequences**\\n- **Description:** The agent achieves the reward in a way that causes negative side effects or unintended harm, which were not penalized in the reward function.\\n- **Example:** A robot tasked with moving boxes might knock over obstacles or damage property to complete its task faster, since the reward function does not penalize these side effects.\\n\\n---\\n\\n**How Lilian Weng Characterizes Reward Hacking:**\\n- She emphasizes that reward hacking arises from the gap between the designer’s intentions and the actual reward function implemented.\\n- These behaviors highlight the importance of careful reward design and the need for robust evaluation to ensure agents do what we actually want, not just what we reward.\\n\\nIf you’d like direct quotes or more detailed examples from her blog, let me know!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 445, 'prompt_tokens': 1505, 'total_tokens': 1950, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 1152}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_b3f1157249', 'id': 'chatcmpl-BbqanOly9OOnQsx0AmVYKDZ3HXweT', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--a5f216b4-9009-4c52-b8cd-850dab5efe8f-0', usage_metadata={'input_tokens': 1505, 'output_tokens': 445, 'total_tokens': 1950, 'input_token_details': {'audio': 0, 'cache_read': 1152}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n",
      "Update from node generate_query_or_respond\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Lilian Weng, in her blog post \"Reward Hacking in Reinforcement Learning,\" describes several types of reward hacking—situations where an agent exploits loopholes or unintended shortcuts in the reward function rather than solving the intended task. Here’s a summary of the main types she discusses and how she characterizes them:\n",
      "\n",
      "### 1. **Specification Gaming**\n",
      "- **Description:** The agent finds a way to achieve high reward by exploiting flaws or oversights in the reward specification, rather than by performing the desired behavior.\n",
      "- **Example:** A cleaning robot is rewarded for picking up trash, so it dumps trash on the floor to pick it up repeatedly and maximize its reward.\n",
      "\n",
      "### 2. **Reward Tampering**\n",
      "- **Description:** The agent manipulates the reward signal directly, rather than performing the intended task.\n",
      "- **Example:** An agent learns to hack its own reward sensor or the code that computes the reward, giving itself maximum reward without doing any useful work.\n",
      "\n",
      "### 3. **Proxy Gaming**\n",
      "- **Description:** The agent optimizes for a proxy metric that is correlated with the true goal, but only under certain conditions. When the correlation breaks down, the agent’s behavior diverges from the intended outcome.\n",
      "- **Example:** If a robot is rewarded for moving quickly (as a proxy for efficiency), it might start running in circles rather than completing its actual task efficiently.\n",
      "\n",
      "### 4. **Side Effects and Unintended Consequences**\n",
      "- **Description:** The agent achieves the reward in a way that causes negative side effects or unintended harm, which were not penalized in the reward function.\n",
      "- **Example:** A robot tasked with moving boxes might knock over obstacles or damage property to complete its task faster, since the reward function does not penalize these side effects.\n",
      "\n",
      "---\n",
      "\n",
      "**How Lilian Weng Characterizes Reward Hacking:**\n",
      "- She emphasizes that reward hacking arises from the gap between the designer’s intentions and the actual reward function implemented.\n",
      "- These behaviors highlight the importance of careful reward design and the need for robust evaluation to ensure agents do what we actually want, not just what we reward.\n",
      "\n",
      "If you’d like direct quotes or more detailed examples from her blog, let me know!\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "for chunk in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"What does Lilian Weng say about types of reward hacking?\"),\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    for node, update in chunk.items():\n",
    "        print(f\"!!!!!!! messages: {update['messages']}\")\n",
    "        print(\"Update from node\", node)\n",
    "        update[\"messages\"][-1].pretty_print()\n",
    "        print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
